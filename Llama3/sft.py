import os
import torch
from contextlib import nullcontext
import logging

from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline, logging
from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model 
from datasets import load_dataset
from trl import (
    ModelConfig,
    ScriptArguments,
    SFTConfig,
    SFTTrainer,
    TrlParser,
    get_kbit_device_map,
    get_peft_config,
    get_quantization_config,
)

# TRL_USE_RICH = os.environ.get("TRL_USE_RICH", False)
# if TRL_USE_RICH:
#     init_zero_verbose()
#     FORMAT = "%(message)s"

#     from rich.console import Console
#     from rich.logging import RichHandler

from tqdm.rich import tqdm
tqdm.pandas()

# if TRL_USE_RICH:
#     logging.basicConfig(format=FORMAT, datefmt="[%X]", handlers=[RichHandler()], level=logging.INFO)

if __name__ == "__main__":
    #parser = TrlParser((SftScriptArguments, TrainingArguments, ModelConfig))
    parser = TrlParser((ScriptArguments, SFTConfig, ModelConfig))
    args, training_args, model_config = parser.parse_args_and_config()

    # Display args
    print('Args:')
    print(args)
    print(training_args)
    print(model_config)

    # Force use our print callback
    # if TRL_USE_RICH:
    #     training_args.disable_tqdm = True
    #     console = Console()

    # Model & Tokenizer
    torch_dtype = (
        model_config.torch_dtype
        if model_config.torch_dtype in ["auto", None]
        else getattr(torch, model_config.torch_dtype)
    )
    # quantization_config = get_quantization_config(model_config)
    quantization_config = None
    
    model_kwargs = dict(
        revision=model_config.model_revision,
        trust_remote_code=model_config.trust_remote_code,
        attn_implementation=model_config.attn_implementation,
        torch_dtype=torch_dtype,
        use_cache=False if training_args.gradient_checkpointing else True,
        device_map=get_kbit_device_map() if quantization_config is not None else None,
        quantization_config=quantization_config,
    )
    tokenizer = AutoTokenizer.from_pretrained(model_config.model_name_or_path, use_fast=True)
    tokenizer.pad_token = tokenizer.eos_token

    # Dataset
    train_dataset = load_dataset('json', data_files={'train': args.dataset_name}, field='train', split='train')
    eval_dataset = load_dataset('json', data_files={'eval': args.dataset_name}, field='eval', split='eval')

    # Optional rich context managers
    # init_context = nullcontext() if not TRL_USE_RICH else console.status("[bold green]Initializing the SFTTrainer...")
    # save_context = (
    #     nullcontext()
    #     if not TRL_USE_RICH
    #     else console.status(f"[bold green]Training completed! Saving the model to {training_args.output_dir}")
    # )

    # Training
    # with init_context:
    trainer = SFTTrainer(
        model=model_config.model_name_or_path,
        model_init_kwargs=model_kwargs,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        tokenizer=tokenizer,
        peft_config=get_peft_config(model_config),
    )

    trainer.train()

    # with save_context:
    trainer.save_model(training_args.output_dir)